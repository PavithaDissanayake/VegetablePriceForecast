{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9220444,"sourceType":"datasetVersion","datasetId":5574487}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\nfile_path = '/kaggle/input/vegi-price/beans-with-dollar.csv'\ndf = pd.read_csv(file_path)\n\n# Display the first few rows of the dataframe to understand its structure\ndf.head(), df.info()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-21T19:45:28.459017Z","iopub.execute_input":"2024-08-21T19:45:28.459362Z","iopub.status.idle":"2024-08-21T19:45:28.902228Z","shell.execute_reply.started":"2024-08-21T19:45:28.459333Z","shell.execute_reply":"2024-08-21T19:45:28.901125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\n\n# Normalize the data (including Kandy, Dambulla, and Exchange Rate)\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(df[['Kandy', 'Dambulla', 'Exchange Rate']])\n\n# Function to create sequences for LSTM\ndef create_sequences(data, seq_length):\n    X = []\n    y = []\n    for i in range(len(data) - seq_length):\n        X.append(data[i:i+seq_length])  # Input sequence\n        y.append(data[i+seq_length][:2])    # Target sequence (next step)\n    return np.array(X), np.array(y)\n\n# Define sequence length\nseq_length = 30\n\n# Create sequences\nX, y = create_sequences(scaled_data, seq_length)\n\n# Split the data into training and test sets\nsplit_ratio = 0.8\nsplit_index = int(len(X) * split_ratio)\nX_train, X_test = X[:split_index], X[split_index:]\ny_train, y_test = y[:split_index], y[split_index:]\n\n# Display the shape of the resulting arrays\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n","metadata":{"execution":{"iopub.status.busy":"2024-08-21T19:45:40.054345Z","iopub.execute_input":"2024-08-21T19:45:40.055259Z","iopub.status.idle":"2024-08-21T19:45:40.668560Z","shell.execute_reply.started":"2024-08-21T19:45:40.055212Z","shell.execute_reply":"2024-08-21T19:45:40.667368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert 'Date' to datetime format\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# Check for missing values\nmissing_values = df.isnull().sum()\n\n# Display the result\ndf.set_index('Date', inplace=True)\ndf = df[['Kandy', 'Dambulla', 'Exchange Rate']]  # We will focus on these two columns for LSTM\nmissing_values, df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T19:45:45.347511Z","iopub.execute_input":"2024-08-21T19:45:45.348270Z","iopub.status.idle":"2024-08-21T19:45:45.367308Z","shell.execute_reply.started":"2024-08-21T19:45:45.348232Z","shell.execute_reply":"2024-08-21T19:45:45.366155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras import mixed_precision\nimport keras_tuner as kt\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Enable mixed precision training\nmixed_precision.set_global_policy('mixed_float16')\n\n# Define a function that builds the LSTM model with hyperparameters\ndef build_model(hp):\n    model = Sequential()\n    model.add(LSTM(units=hp.Int('units', min_value=16, max_value=64, step=16),\n                   return_sequences=True, input_shape=(seq_length, 3)))\n    model.add(Dropout(hp.Float('dropout_rate1', 0.1, 0.5, step=0.1)))\n    \n    model.add(LSTM(units=hp.Int('units2', min_value=16, max_value=64, step=16), return_sequences=False))\n    model.add(Dropout(hp.Float('dropout_rate2', 0.1, 0.5, step=0.1)))\n    \n    model.add(Dense(units=hp.Int('dense_units', min_value=16, max_value=64, step=16), activation='relu'))\n    model.add(Dense(2, dtype='float32'))  # Output layer\n\n    # Compile the model\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    \n    return model\n\n# Define a tuner using RandomSearch\ntuner = kt.RandomSearch(\n    build_model,\n    objective='val_loss',\n    max_trials=10,  # The number of different hyperparameter combinations to try\n    executions_per_trial=2,  # Number of models to train per trial (to reduce variance)\n    directory='my_dir',  # Directory to save search logs\n    project_name='lstm_hyperparameter_tuning'\n)\n\n# Convert data to tf.data pipelines (as before)\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16).prefetch(tf.data.AUTOTUNE)\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(16).prefetch(tf.data.AUTOTUNE)\n\n# Run the hyperparameter search\ntuner.search(train_dataset, epochs=20, validation_data=test_dataset, callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n\n# Retrieve the best model\nbest_model = tuner.get_best_models(num_models=1)[0]\n\n# Print the best hyperparameters\nbest_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\nprint(f\"Best Hyperparameters: {best_hps.values}\")\n\n# Optionally, retrain the best model\nhistory = best_model.fit(train_dataset, epochs=20, validation_data=test_dataset, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-21T19:45:50.346966Z","iopub.execute_input":"2024-08-21T19:45:50.347737Z","iopub.status.idle":"2024-08-21T19:46:11.659387Z","shell.execute_reply.started":"2024-08-21T19:45:50.347701Z","shell.execute_reply":"2024-08-21T19:46:11.658325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test dataset\npredictions = best_model.predict(test_dataset)\n\n# Optionally, you can also predict on a single batch of test data:\n# predictions = model.predict(X_test[:batch_size])\n\n# Print the predictions\nprint(predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-21T19:46:22.768886Z","iopub.execute_input":"2024-08-21T19:46:22.770150Z","iopub.status.idle":"2024-08-21T19:46:23.224635Z","shell.execute_reply.started":"2024-08-21T19:46:22.770113Z","shell.execute_reply":"2024-08-21T19:46:23.223554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_rescaled = scaler.inverse_transform(\n    np.concatenate([predictions, np.zeros((predictions.shape[0], 1))], axis=1)\n)[:, :2]\n\nprint(\"Rescaled Predictions:\", predictions_rescaled)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T19:47:20.600639Z","iopub.execute_input":"2024-08-21T19:47:20.601631Z","iopub.status.idle":"2024-08-21T19:47:20.617374Z","shell.execute_reply.started":"2024-08-21T19:47:20.601594Z","shell.execute_reply":"2024-08-21T19:47:20.616238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Rescale the predictions and y_test to original scale\ny_test_rescaled = scaler.inverse_transform(\n    np.concatenate([y_test, np.zeros((y_test.shape[0], 1))], axis=1)\n)[:, :2]\n\n\n\n# Create two subplots for 'Kandy' and 'Dambulla'\nfig, ax = plt.subplots(2, 1, figsize=(14, 10))\n\n# Plot for Kandy\nax[0].plot(y_test_rescaled[:, 0], color='blue', label='True Kandy')\nax[0].plot(predictions_rescaled[:, 0], color='red', linestyle='--', label='Predicted Kandy')\nax[0].set_title('True vs Predicted Values for Kandy')\nax[0].set_xlabel('Time')\nax[0].set_ylabel('Kandy Values')\nax[0].legend()\n\n# Plot for Dambulla\nax[1].plot(y_test_rescaled[:, 1], color='green', label='True Dambulla')\nax[1].plot(predictions_rescaled[:, 1], color='orange', linestyle='--', label='Predicted Dambulla')\nax[1].set_title('True vs Predicted Values for Dambulla')\nax[1].set_xlabel('Time')\nax[1].set_ylabel('Dambulla Values')\nax[1].legend()\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-21T19:47:43.276773Z","iopub.execute_input":"2024-08-21T19:47:43.277607Z","iopub.status.idle":"2024-08-21T19:47:44.173875Z","shell.execute_reply.started":"2024-08-21T19:47:43.277569Z","shell.execute_reply":"2024-08-21T19:47:44.172731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\n\n\n# Calculate the Mean Squared Error (MSE) for each target ('Kandy' and 'Dambulla')\nmse_kandy = mean_squared_error(y_test_rescaled[:, 0], predictions_rescaled[:, 0])\nmse_dambulla = mean_squared_error(y_test_rescaled[:, 1], predictions_rescaled[:, 1])\n\n# Print the MSE results\nprint(f\"MSE for Kandy: {mse_kandy}\")\nprint(f\"MSE for Dambulla: {mse_dambulla}\")\n\n# Calculate the RMSE for each target ('Kandy' and 'Dambulla')\nrmse_kandy = np.sqrt(mean_squared_error(y_test_rescaled[:, 0], predictions_rescaled[:, 0]))\nrmse_dambulla = np.sqrt(mean_squared_error(y_test_rescaled[:, 1], predictions_rescaled[:, 1]))\n\n# Print the RMSE results\nprint(f\"RMSE for Kandy: {rmse_kandy}\")\nprint(f\"RMSE for Dambulla: {rmse_dambulla}\")\n\n# Calculate the RMSLE for each target ('Kandy' and 'Dambulla')\nrmsle_kandy = np.sqrt(mean_squared_log_error(y_test_rescaled[:, 0], predictions_rescaled[:, 0]))\nrmsle_dambulla = np.sqrt(mean_squared_log_error(y_test_rescaled[:, 1], predictions_rescaled[:, 1]))\n\n# Print the RMSLE results\nprint(f\"RMSLE for Kandy: {rmsle_kandy}\")\nprint(f\"RMSLE for Dambulla: {rmsle_dambulla}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T19:48:53.486216Z","iopub.execute_input":"2024-08-21T19:48:53.487206Z","iopub.status.idle":"2024-08-21T19:48:53.501749Z","shell.execute_reply.started":"2024-08-21T19:48:53.487162Z","shell.execute_reply":"2024-08-21T19:48:53.500762Z"},"trusted":true},"execution_count":null,"outputs":[]}]}